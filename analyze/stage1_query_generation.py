# -*- coding: utf-8 -*-
"""
LLM-SEO Pipeline Step 1: Query Pool Generator (v2.0 - Bilingual)
-----------------------------------------------------------------
ç”¨é€”ï¼š
ç”Ÿæˆé›™èªæŸ¥è©¢æ± ï¼ˆç¹é«”ä¸­æ–‡ + è‹±æ–‡ï¼‰ï¼Œä¸¦é€²è¡Œèªè¨€åµæ¸¬èˆ‡ Embedding å‘é‡åŒ–ã€‚

æ–°åŠŸèƒ½ï¼š
âœ… æ”¯æ´é›™èªæŸ¥è©¢ç”Ÿæˆï¼ˆ20 ä¸­æ–‡ + 20 è‹±æ–‡ï¼‰
âœ… åˆ†åˆ¥ç®¡ç†ä¸­è‹±æ–‡ç¨®å­æŸ¥è©¢
âœ… è‡ªå‹•èªè¨€æª¢æ¸¬
âœ… çµ±ä¸€ Embedding å‘é‡åŒ–
"""

import os, json, time, sys, io, re
from pathlib import Path
from openai import OpenAI
from tqdm import tqdm
import pandas as pd

# Windows UTF-8 æ”¯æ´
if sys.platform == "win32":
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')

# åŠ å…¥å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ°è·¯å¾‘
ROOT_DIR = Path(__file__).parent.parent.absolute()
sys.path.insert(0, str(ROOT_DIR))

from config.config_loader import config

# =======================================================
# åˆå§‹åŒ–èˆ‡è¨­å®š
# =======================================================
config.data_dir.mkdir(parents=True, exist_ok=True)

print("\n" + "=" * 60)
print("ğŸŒ é›™èªæŸ¥è©¢æ± ç”Ÿæˆå™¨")
print("=" * 60)
print(f"ä¸­æ–‡ä¸»é¡Œï¼š{config.topic}")
print(f"è‹±æ–‡ä¸»é¡Œï¼š{config.topic_en}")
print(f"ç›®æ¨™æŸ¥è©¢æ•¸é‡ï¼š{config.query_pool_size}")
print(f"  - ç¹é«”ä¸­æ–‡ï¼š{config.zh_tw_queries}")
print(f"  - è‹±æ–‡ï¼š{config.en_queries}")

# åˆå§‹åŒ– OpenAI
client = OpenAI(api_key=config.get_openai_key())

# =======================================================
# æŸ¥è©¢ç¨®å­è¨­å®š
# =======================================================
BASE_SEEDS_ZH = config.base_seeds_zh
BASE_SEEDS_EN = config.base_seeds_en

print(f"\nğŸ“Œ ç¨®å­æŸ¥è©¢æ•¸é‡ï¼š")
print(f"  - ä¸­æ–‡ç¨®å­ï¼š{len(BASE_SEEDS_ZH)}")
print(f"  - è‹±æ–‡ç¨®å­ï¼š{len(BASE_SEEDS_EN)}")

# =======================================================
# æŸ¥è©¢ç”Ÿæˆæç¤ºè©
# =======================================================

PROMPT_ZH = """è«‹ç”¢å‡º {n} æ¢èˆ‡ã€Œ{topic}ã€ç›¸é—œçš„**ç¹é«”ä¸­æ–‡**æŸ¥è©¢ã€‚

**å¿…é ˆæ¶µè“‹çš„ 6 å¤§é¡åˆ¥**ï¼ˆæ¯é¡è‡³å°‘ 2-3 æ¢ï¼‰ï¼š
1. ç”¢å“å®šç¾©èˆ‡è¦æ ¼ - æè³ªã€å®¹é‡ã€å°ºå¯¸ã€å£“åŠ›ã€æº«åº¦ç­‰æŠ€è¡“è¦æ ¼ç›¸é—œæŸ¥è©¢
2. æ‡‰ç”¨å ´æ™¯ - å¯¦éš›ä½¿ç”¨æƒ…å¢ƒã€é©ç”¨å°è±¡ã€æ»…èŒ/è™•ç†å°è±¡ç­‰æ‡‰ç”¨ç›¸é—œæŸ¥è©¢
3. é¸è³¼æŒ‡å— - å¦‚ä½•é¸æ“‡ã€è¦æ ¼æ¯”è¼ƒã€é¸è³¼è¦ç´ ï¼ˆé¿å…å“ç‰Œæ¨è–¦ï¼‰
4. ä¿é¤Šç¶­è­· - æ¸…æ½”ã€æ ¡æ­£ã€æ•…éšœæ’é™¤ã€å„²å­˜æ¢ä»¶ç›¸é—œæŸ¥è©¢
5. å¸¸è¦‹å•é¡Œ (FAQ) - ç‚ºä»€éº¼ã€å¦‚ä½•è§£æ±ºã€å®‰å…¨æ³¨æ„äº‹é …ã€ä½¿ç”¨æœŸé™ç­‰ç–‘å•
6. æ‡‰ç”¨æ¨™æº–èˆ‡æµç¨‹ - æ“ä½œæ­¥é©Ÿã€æª¢æ¸¬ç›®æ¨™ã€å“è³ªæ§åˆ¶ç›¸é—œæŸ¥è©¢

**é‡è¦è¦å‰‡**ï¼š
1. åªç”¢å‡ºç¹é«”ä¸­æ–‡æŸ¥è©¢ï¼Œä¸è¦ç”¢å‡ºè‹±æ–‡æŸ¥è©¢
2. ä½¿ç”¨å°ç£å¸¸ç”¨è¡“èª
3. æ¯è¡Œä¸€æ¢æŸ¥è©¢ï¼Œè«‹å‹¿åŠ ç·¨è™Ÿã€å¼•è™Ÿæˆ–æ¨™é»
4. æŸ¥è©¢è¦è‡ªç„¶ã€ç¬¦åˆå°ç£ä½¿ç”¨è€…çš„æœå°‹ç¿’æ…£
5. é¿å…ã€Œå“ç‰Œã€ã€ã€Œå» å•†ã€ã€ã€Œåƒ¹æ ¼ã€ã€ã€Œå“ªè£¡è²·ã€ç­‰å•†æ¥­åŒ–è©å½™
6. æ‡‰ç”¨å ´æ™¯ç¯„ä¾‹åƒ…ä¾›åƒè€ƒï¼Œè«‹æ ¹æ“šç”¢å“ç‰¹æ€§ç”Ÿæˆåˆé©çš„æŸ¥è©¢

ç›´æ¥è¼¸å‡ºæŸ¥è©¢ï¼Œä¸éœ€è¦ä»»ä½•å‰è¨€æˆ–èªªæ˜ã€‚"""

PROMPT_EN = """Generate {n} queries related to "{topic}" in **English**.

**Must cover these 6 categories** (at least 2-3 queries per category):
1. Product Definition & Specifications - material, capacity, size, pressure, temperature specs
2. Application Scenarios - medical instruments, laboratory, food processing, specific use cases
3. Buying Guide - how to choose, spec comparison, selection factors (avoid brand recommendations)
4. Maintenance - cleaning, calibration, troubleshooting, storage conditions
5. FAQs - why, how to solve, safety precautions, lifespan
6. Standards & Procedures - operation steps, testing targets, quality control

**Important rules**:
1. Only generate English queries, no Chinese
2. Use international standard terminology
3. One query per line, no numbering or quotes
4. Natural search queries that users would type
5. Avoid "brand", "vendor", "price", "where to buy" commercial terms

Output queries directly, no preamble needed."""

# =======================================================
# ç”ŸæˆæŸ¥è©¢æ± 
# =======================================================

def generate_queries(topic: str, n: int, language: str = "zh-TW"):
    """
    ç”ŸæˆæŸ¥è©¢

    Args:
        topic: ä¸»é¡Œ
        n: ç”Ÿæˆæ•¸é‡
        language: zh-TW æˆ– en

    Returns:
        æŸ¥è©¢åˆ—è¡¨
    """
    if language == "zh-TW":
        prompt_template = PROMPT_ZH
        seeds = BASE_SEEDS_ZH
        lang_name = "ç¹é«”ä¸­æ–‡"
    else:
        prompt_template = PROMPT_EN
        seeds = BASE_SEEDS_EN
        lang_name = "English"

    print(f"\nğŸ¤– ç”Ÿæˆ {lang_name} æŸ¥è©¢ï¼ˆä¸»é¡Œï¼š{topic}ï¼‰...")

    prompt = prompt_template.format(topic=topic, n=n)
    resp = client.chat.completions.create(
        model=config.dspy_model_small,
        messages=[{"role": "user", "content": prompt}],
        temperature=0.7
    )

    text = resp.choices[0].message.content.strip()
    extra = [q.strip() for q in text.splitlines() if q.strip()]

    # åˆä½µç¨®å­ + ç”Ÿæˆçš„æŸ¥è©¢
    queries = seeds + extra

    print(f"âœ… LLM ç”Ÿæˆ {len(extra)} æ¢æŸ¥è©¢")
    print(f"âœ… ç¸½è¨ˆ {len(queries)} æ¢æŸ¥è©¢ï¼ˆå«ç¨®å­ï¼‰")

    # å»é‡
    return list(dict.fromkeys(queries))

# =======================================================
# èªè¨€æª¢æ¸¬
# =======================================================

def detect_language(q: str) -> str:
    """
    æª¢æ¸¬æŸ¥è©¢èªè¨€

    Returns:
        "zh-TW" æˆ– "en"
    """
    # æª¢æŸ¥æ˜¯å¦åŒ…å«ä¸­æ–‡å­—ç¬¦
    has_chinese = bool(re.search(r'[\u4e00-\u9fff]', q))

    if has_chinese:
        return "zh-TW"
    else:
        return "en"

def enrich_language(q: str):
    """
    ç‚ºæŸ¥è©¢æ·»åŠ èªè¨€æ¨™è¨˜

    Returns:
        {"query": str, "lang": str} æˆ– None
    """
    lang = detect_language(q)
    return {"query": q, "lang": lang}

# =======================================================
# Embedding å‘é‡åŒ–
# =======================================================

def embed_query(q: str):
    """ç”Ÿæˆ Embedding å‘é‡"""
    try:
        resp = client.embeddings.create(
            model="text-embedding-3-large",
            input=q
        )
        return resp.data[0].embedding
    except Exception as e:
        print(f"âš ï¸ å‘é‡ç”Ÿæˆå¤±æ•—ï¼š{q} ({e})")
        return None

# =======================================================
# ä¸»åŸ·è¡Œå€å¡Š
# =======================================================

def main():
    print("\n" + "=" * 60)
    print("ğŸš€ é–‹å§‹ç”Ÿæˆé›™èªæŸ¥è©¢æ± ")
    print("=" * 60)

    # ç”Ÿæˆä¸­æ–‡æŸ¥è©¢
    zh_queries = generate_queries(
        topic=config.topic,
        n=config.zh_tw_queries,
        language="zh-TW"
    )

    # ç”Ÿæˆè‹±æ–‡æŸ¥è©¢
    en_queries = generate_queries(
        topic=config.topic_en,
        n=config.en_queries,
        language="en"
    )

    # åˆä½µæ‰€æœ‰æŸ¥è©¢
    all_queries = zh_queries + en_queries

    print("\n" + "=" * 60)
    print(f"ğŸ“Š æŸ¥è©¢æ± çµ±è¨ˆ")
    print("=" * 60)
    print(f"ç¹é«”ä¸­æ–‡ï¼š{len(zh_queries)} æ¢")
    print(f"Englishï¼š{len(en_queries)} æ¢")
    print(f"ç¸½è¨ˆï¼š{len(all_queries)} æ¢")

    # èªè¨€æª¢æ¸¬èˆ‡æ¨™è¨˜
    print("\nğŸŒ é€²è¡Œèªè¨€æª¢æ¸¬...")
    enriched = []
    for q in tqdm(all_queries, desc="Language detection"):
        result = enrich_language(q)
        if result:
            enriched.append(result)

    # çµ±è¨ˆèªè¨€åˆ†å¸ƒ
    zh_count = sum(1 for item in enriched if item["lang"] == "zh-TW")
    en_count = sum(1 for item in enriched if item["lang"] == "en")

    print(f"âœ… èªè¨€æª¢æ¸¬å®Œæˆ")
    print(f"   ç¹é«”ä¸­æ–‡ï¼š{zh_count} æ¢")
    print(f"   Englishï¼š{en_count} æ¢")

    # Embedding å‘é‡åŒ–
    print("\nğŸ§  å»ºç«‹ Embedding å‘é‡ä¸­...")
    vectors = {}

    for item in tqdm(enriched, desc="Embedding"):
        q = item["query"]
        vec = embed_query(q)
        if vec:
            vectors[q] = vec
        time.sleep(0.5)  # API é™æµä¿è­·

    # å„²å­˜æª”æ¡ˆ
    csv_path = config.data_dir / config.output_files["query_pool"]
    json_path = config.data_dir / config.output_files["query_vectors"]

    df = pd.DataFrame(enriched)
    df.to_csv(csv_path, index=False, encoding="utf-8-sig")

    with open(json_path, "w", encoding="utf-8") as f:
        json.dump(vectors, f, ensure_ascii=False, indent=2)

    # çµæœå ±å‘Š
    print("\n" + "=" * 60)
    print("âœ… é›™èªæŸ¥è©¢æ± å»ºç«‹å®Œæˆï¼")
    print("=" * 60)
    print(f"ğŸ“ {csv_path}ï¼ˆ{len(df)} æ¢ï¼‰")
    print(f"ğŸ“ {json_path}ï¼ˆ{len(vectors)} æ¢ï¼‰")
    print(f"\nğŸ“Š æœ€çµ‚çµ±è¨ˆï¼š")
    print(f"   ç¹é«”ä¸­æ–‡ï¼š{zh_count} æ¢")
    print(f"   Englishï¼š{en_count} æ¢")
    print(f"   å‘é‡è¦†è“‹ç‡ï¼š{len(vectors)}/{len(df)} ({len(vectors)/len(df)*100:.1f}%)")

    # é©—è­‰
    if len(df) == len(vectors):
        print("\nğŸ§© é©—è­‰æˆåŠŸï¼šæŸ¥è©¢èˆ‡å‘é‡æ•¸é‡ä¸€è‡´ âœ…")
    else:
        missing = len(df) - len(vectors)
        print(f"\nâš ï¸ æœ‰ {missing} æ¢æŸ¥è©¢ç¼ºå°‘å‘é‡")

    print("\n" + "=" * 60)
    print("ğŸ‰ å®Œæˆï¼")
    print("=" * 60)

# =======================================================
if __name__ == "__main__":
    main()
