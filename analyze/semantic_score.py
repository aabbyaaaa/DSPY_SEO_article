"""
LLM-SEO Pipeline Step 3: Semantic Scoring (v1.3 - Config Unified)
-----------------------------------------------------------------
ä»¥ Coverage + Relevance + Density ä¸‰æŒ‡æ¨™ç¶œåˆè©•åˆ†æŸ¥è©¢æ½›åŠ›ã€‚

è¨­å®šï¼š
- Coverageï¼šä½¿ç”¨ Tavily API å¯¦éš›æŠ“å–æœå°‹çµæœæ•¸
- Relevanceï¼šEmbedding + GPT æ··åˆæ‰“åˆ†ï¼ˆ20 æ¢æ¨£æœ¬ï¼‰
- Densityï¼šEmbedding ç¾¤èšå¯†åº¦
- æ‰€æœ‰é…ç½®å¾ config_loader çµ±ä¸€è¼‰å…¥
"""

import os, json, time, sys, io, numpy as np, pandas as pd
from pathlib import Path
from openai import OpenAI
from tavily import TavilyClient
from sklearn.cluster import KMeans
from sklearn.metrics.pairwise import cosine_similarity
from tqdm import tqdm

# Windows UTF-8 æ”¯æ´
if sys.platform == "win32":
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')

# åŠ å…¥å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ°è·¯å¾‘
ROOT_DIR = Path(__file__).parent.parent.absolute()
sys.path.insert(0, str(ROOT_DIR))

from config.config_loader import config

# =======================================================
# åˆå§‹åŒ– API
# =======================================================
print("\nInitializing Semantic Scoring Module...")

tavily = TavilyClient(api_key=config.get_tavily_key())
client = OpenAI(api_key=config.get_openai_key())

print(f"ä¸»é¡Œï¼š{config.topic}")
print(f"æ¬Šé‡é…ç½® - Coverage: {config.coverage_w}, Relevance: {config.relevance_w}, Density: {config.density_w}")
print(f"æ··åˆè©•åˆ† - Embedding: {config.embedding_weight}, LLM: {config.llm_weight}")

# =======================================================
# è¼‰å…¥æŸ¥è©¢æ± èˆ‡å‘é‡
# =======================================================
pool_path = config.data_dir / config.output_files["query_pool"]
vec_path = config.data_dir / config.output_files["query_vectors"]

if not pool_path.exists():
    raise FileNotFoundError(f"âŒ æ‰¾ä¸åˆ° {pool_path}ï¼Œè«‹å…ˆåŸ·è¡Œ analyze/queries.py")
if not vec_path.exists():
    raise FileNotFoundError(f"âŒ æ‰¾ä¸åˆ° {vec_path}ï¼Œè«‹å…ˆåŸ·è¡Œ analyze/queries.py")

pool_df = pd.read_csv(pool_path)
with open(vec_path, "r", encoding="utf-8") as f:
    vecs = json.load(f)

queries = pool_df["query"].tolist()
vectors = np.array([vecs[q] for q in queries])

# å¿«å–æª”æ¡ˆ
cache_tavily = config.data_dir / "cache_tavily.json"
cache_relevance = config.data_dir / "cache_relevance.json"

tavily_cache = json.load(open(cache_tavily, "r", encoding="utf-8")) if cache_tavily.exists() else {}
relevance_cache = json.load(open(cache_relevance, "r", encoding="utf-8")) if cache_relevance.exists() else {}

# =======================================================
# Step 1ï¸âƒ£ Coverage Score - Tavily æœå°‹è¦†è“‹åº¦
# =======================================================
coverage_scores = {}
print("\nğŸŒ [Step 1] Tavily Coverage æª¢æŸ¥ä¸­...")

for q in tqdm(queries, desc="Tavily Search"):
    if q in tavily_cache:
        coverage_scores[q] = tavily_cache[q]
        continue
    try:
        res = tavily.search(q, max_results=10)
        num = len(res.get("results", []))
        score = min(num / 10 * 5, 5)
        coverage_scores[q] = round(score, 2)
        tavily_cache[q] = coverage_scores[q]
        time.sleep(0.5)
    except Exception as e:
        coverage_scores[q] = 0
        print(f"âŒ Tavily error @ {q}: {e}")

with open(cache_tavily, "w", encoding="utf-8") as f:
    json.dump(tavily_cache, f, ensure_ascii=False, indent=2)

# =======================================================
# Step 2ï¸âƒ£ Relevance Score - Embedding + GPT æ··åˆ
# =======================================================
print("\nğŸ§  [Step 2] è¨ˆç®— Relevance åˆ†æ•¸ï¼ˆEmbedding + GPT æ··åˆï¼‰...")

topic_vec = np.mean(vectors, axis=0)
similarities = cosine_similarity(vectors, topic_vec.reshape(1, -1)).flatten()
embed_scores = (similarities * 5).clip(0, 5)

# åˆ†ç¾¤æŠ½æ¨£ï¼ˆ20 æ¢ï¼‰
kmeans = KMeans(n_clusters=5, random_state=42, n_init="auto").fit(vectors)
sample_indices = []
for i in range(5):
    cluster_indices = np.where(kmeans.labels_ == i)[0]
    picks = np.random.choice(cluster_indices, size=min(4, len(cluster_indices)), replace=False)
    sample_indices.extend(picks)
sample_queries = [queries[i] for i in sample_indices]

# GPT æ‰“åˆ†
for q in tqdm(sample_queries, desc=f"{config.dspy_model_small} è©•åˆ†"):
    if q in relevance_cache:
        continue
    prompt = f"""ä¸»é¡Œç‚ºã€Œ{config.topic}ã€ã€‚
è«‹ä»¥ 0â€“5 åˆ†è©•ä¼°ä»¥ä¸‹æŸ¥è©¢èˆ‡ä¸»é¡Œçš„èªæ„ç›¸é—œç¨‹åº¦ã€‚
æŸ¥è©¢ï¼šã€Œ{q}ã€"""
    try:
        resp = client.chat.completions.create(
            model=config.dspy_model_small,  # ä½¿ç”¨é…ç½®çš„å°æ¨¡å‹
            messages=[{"role": "user", "content": prompt}],
            temperature=0
        )
        txt = resp.choices[0].message.content.strip()
        score = next((int(c) for c in txt if c.isdigit()), 3)
        relevance_cache[q] = score
        time.sleep(0.5)
    except Exception as e:
        relevance_cache[q] = 3
        print(f"âŒ GPT error @ {q}: {e}")

with open(cache_relevance, "w", encoding="utf-8") as f:
    json.dump(relevance_cache, f, ensure_ascii=False, indent=2)

# æ··åˆåŠ æ¬Šï¼ˆä½¿ç”¨é…ç½®çš„æ¬Šé‡ï¼‰
relevance_scores = []
for q, emb_score in zip(queries, embed_scores):
    if q in relevance_cache:
        llm_score = relevance_cache[q]
    else:
        q_vec = np.array(vecs[q]).reshape(1, -1)
        sample_vecs = np.array([vecs[sq] for sq in sample_queries])
        sims = cosine_similarity(q_vec, sample_vecs).flatten()
        nearest = np.argmax(sims)
        llm_score = relevance_cache.get(sample_queries[nearest], 3)
    final_score = config.embedding_weight * emb_score + config.llm_weight * llm_score
    relevance_scores.append(round(final_score, 2))

# =======================================================
# Step 3ï¸âƒ£ Density Score - ç¾¤èšå¯†åº¦
# =======================================================
print("\nğŸ” [Step 3] è¨ˆç®— Densityï¼ˆç¾¤èšå¯†åº¦ï¼‰...")
cos_matrix = cosine_similarity(vectors)
density_raw = cos_matrix.mean(axis=1)
density_norm = (density_raw / density_raw.max()) * 5
density_scores = [round(s, 2) for s in density_norm]

# =======================================================
# Step 4ï¸âƒ£ ç¶œåˆè©•åˆ†ï¼ˆä½¿ç”¨é…ç½®çš„æ¬Šé‡ï¼‰
# =======================================================
final_scores, decisions = [], []
for q in queries:
    c = coverage_scores.get(q, 0)
    r = relevance_scores[queries.index(q)]
    d = density_scores[queries.index(q)]
    score = round(
        c * config.coverage_w +
        r * config.relevance_w +
        d * config.density_w, 2
    )
    if score >= 4.0:
        decision = "âœ… é«˜æ½›åŠ›"
    elif score >= 3.0:
        decision = "ğŸŸ¡ ä¸­æ½›åŠ›"
    elif score >= 2.0:
        decision = "âšª ä½æ½›åŠ›"
    else:
        decision = "ğŸ”´ ç„¡æ½›åŠ›"
    final_scores.append(score)
    decisions.append(decision)

# =======================================================
# Step 5ï¸âƒ£ è¼¸å‡ºçµæœ
# =======================================================
out_df = pd.DataFrame({
    "query": queries,
    "coverage": [coverage_scores.get(q, 0) for q in queries],
    "relevance": relevance_scores,
    "density": density_scores,
    "score": final_scores,
    "decision": decisions
})
out_path = config.data_dir / "semantic_scores.csv"
out_df.to_csv(out_path, index=False, encoding="utf-8-sig")

high_count = sum(out_df["score"] >= 4.0)
avg_score = round(out_df["score"].mean(), 2)

print("\nâœ… å·²å®Œæˆèªæ„æ½›åŠ›æ‰“åˆ†ï¼")
print(f"å…±è™•ç† {len(queries)} æ¢æŸ¥è©¢ã€‚")
print(f"å¹³å‡åˆ†æ•¸ï¼š{avg_score}")
print(f"é«˜æ½›åŠ›æŸ¥è©¢ï¼š{high_count} æ¢ï¼ˆå·²æ¨™ç¤º âœ…ï¼‰")
print(f"è¼¸å‡ºæª”æ¡ˆï¼š{out_path}\n")
