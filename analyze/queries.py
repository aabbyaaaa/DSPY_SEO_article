"""
LLM-SEO Pipeline Step 1: Query Pool Generator (v1.4)
---------------------------------------------------
ç”¨é€”ï¼š
ä¾æ“šè¨­å®šä¸»é¡Œ (config/settings.yaml) + æ‰‹å‹•å®šç¾©çš„ BASE_SEEDSï¼Œ
ç”Ÿæˆä¸­è‹±æ··åˆçš„æŸ¥è©¢æ± ï¼Œä¸¦é€²è¡Œèªè¨€åµæ¸¬ã€åå‘ç¿»è­¯èˆ‡ Embedding å‘é‡åŒ–ã€‚

é‡è¦åŸå‰‡ï¼š
âœ… LLM åªã€Œç†è§£ topicã€ï¼Œä¸æœƒè‡ªå‹•å¡å…¥ BASE_SEEDSã€‚
âœ… BASE_SEEDS å®Œå…¨ç”±ä½¿ç”¨è€…äººå·¥æ§åˆ¶ï¼ˆé¿å…èªç¾©åç§»ï¼‰ã€‚
âœ… çµ±ä¸€ä½¿ç”¨ config_loader è¼‰å…¥é…ç½®ã€‚
"""

import os, json, time, sys, io, re
from pathlib import Path
from openai import OpenAI
from tqdm import tqdm
import pandas as pd

# Windows UTF-8 æ”¯æ´
if sys.platform == "win32":
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')

# åŠ å…¥å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ°è·¯å¾‘ï¼Œç¢ºä¿å¯ä»¥è¼‰å…¥ config
ROOT_DIR = Path(__file__).parent.parent.absolute()
sys.path.insert(0, str(ROOT_DIR))

from config.config_loader import config

# =======================================================
# åˆå§‹åŒ–èˆ‡è¨­å®š
# =======================================================
# ç¢ºä¿è³‡æ–™ç›®éŒ„å­˜åœ¨
config.data_dir.mkdir(parents=True, exist_ok=True)

print(f"ä¸»é¡Œï¼š{config.topic}")
print(f"ç›®æ¨™æŸ¥è©¢æ•¸é‡ï¼š{config.query_pool_size}")

# === åˆå§‹åŒ– OpenAI ===
client = OpenAI(api_key=config.get_openai_key())

# =======================================================
# æŸ¥è©¢ç¨®å­è¨­å®šï¼ˆå¾ settings.yaml è¼‰å…¥ï¼‰
# =======================================================
BASE_SEEDS = config.base_seeds

assert isinstance(BASE_SEEDS, list) and len(BASE_SEEDS) > 0, \
    "âŒ BASE_SEEDS ä¸å¯ç‚ºç©ºï¼Œè«‹åœ¨ config/settings.yaml çš„ query_generation.base_seeds è¨­å®šè‡³å°‘ 1 å€‹æŸ¥è©¢ç¨®å­ã€‚"

print(f"ğŸ“Œ æ‰‹å‹•ç¨®å­æ•¸é‡ï¼š{len(BASE_SEEDS)}")

# =======================================================
# æŸ¥è©¢ç”Ÿæˆæç¤ºè©
# =======================================================
PROMPT = """è«‹ç”¢å‡º {n} æ¢èˆ‡ã€Œ{topic}ã€ç›¸é—œçš„**ç¹é«”ä¸­æ–‡**æŸ¥è©¢ï¼Œ
æ¶µè“‹ è³‡è¨Š/å•†æ¥­/æ¯”è¼ƒ/ç¶­è­·/æ ¡æ­£/éŒ¯èª¤æ’æŸ¥/æ›¿ä»£å“/é…ä»¶/å¸¸è¦‹å•é¡Œã€‚

**é‡è¦è¦å‰‡**ï¼š
1. åªç”¢å‡ºç¹é«”ä¸­æ–‡æŸ¥è©¢ï¼Œä¸è¦ç”¢å‡ºè‹±æ–‡æŸ¥è©¢
2. ä½¿ç”¨å°ç£å¸¸ç”¨è¡“èªï¼ˆä¾‹å¦‚ï¼šå¾®é‡å¸ç®¡ã€ç§»æ¶²ç®¡ã€å¸ç®¡å°–ï¼‰
3. æ¯è¡Œä¸€æ¢æŸ¥è©¢ï¼Œè«‹å‹¿åŠ ç·¨è™Ÿã€å¼•è™Ÿæˆ–æ¨™é»
4. æŸ¥è©¢è¦è‡ªç„¶ã€ç¬¦åˆå°ç£ä½¿ç”¨è€…çš„æœå°‹ç¿’æ…£"""

# =======================================================
# ç”ŸæˆæŸ¥è©¢æ± 
# =======================================================
def generate_queries(topic: str, n: int):
    print(f"\nğŸ¤– ç”ŸæˆæŸ¥è©¢ä¸­ï¼ˆä¸»é¡Œï¼š{topic}ï¼‰...")
    prompt = PROMPT.format(topic=topic, n=n)
    resp = client.chat.completions.create(
        model=config.dspy_model_small,  # ä½¿ç”¨é…ç½®çš„å°æ¨¡å‹
        messages=[{"role": "user", "content": prompt}],
        temperature=0.7
    )
    text = resp.choices[0].message.content.strip()
    extra = [q.strip() for q in text.splitlines() if q.strip()]
    queries = BASE_SEEDS + extra
    print(f"âœ… LLM ç”Ÿæˆ {len(extra)} æ¢æŸ¥è©¢")
    return list(dict.fromkeys(queries))  # å»é‡

# =======================================================
# èªè¨€æª¢æ¸¬ï¼ˆç°¡åŒ–ç‰ˆ - åªè™•ç†ç¹é«”ä¸­æ–‡ï¼‰
# =======================================================
def enrich_language(q):
    """
    ç°¡åŒ–ç‰ˆèªè¨€æª¢æ¸¬ï¼šåªè™•ç†ç¹é«”ä¸­æ–‡æŸ¥è©¢
    ä½¿ç”¨æ­£å‰‡åˆ¤æ–·æ˜¯å¦åŒ…å«ä¸­æ–‡å­—ç¬¦
    """
    # æª¢æŸ¥æ˜¯å¦åŒ…å«ä¸­æ–‡å­—ç¬¦
    has_chinese = bool(re.search(r'[\u4e00-\u9fff]', q))

    if has_chinese:
        # ä¸­æ–‡æŸ¥è©¢ï¼Œç›´æ¥è¿”å›
        return {"query": q, "lang": "zh-TW"}
    else:
        # å¦‚æœå‡ºç¾è‹±æ–‡æŸ¥è©¢ï¼ˆä¸æ‡‰è©²ç™¼ç”Ÿï¼‰ï¼Œç™¼å‡ºè­¦å‘Š
        print(f"âš ï¸ ç™¼ç¾éä¸­æ–‡æŸ¥è©¢ï¼š{q}ï¼Œå°‡è·³éæ­¤æŸ¥è©¢")
        return None

# =======================================================
# Embedding å‘é‡åŒ–
# =======================================================
def embed_query(q):
    try:
        resp = client.embeddings.create(model="text-embedding-3-large", input=q)
        return resp.data[0].embedding
    except Exception as e:
        print(f"âš ï¸ å‘é‡ç”Ÿæˆå¤±æ•—ï¼š{q} ({e})")
        return None

# =======================================================
# ä¸»åŸ·è¡Œå€å¡Š
# =======================================================
def main():
    all_queries = generate_queries(config.topic, config.query_pool_size)
    enriched = []
    vectors = {}

    print("\nğŸŒ æª¢æŸ¥æŸ¥è©¢èªè¨€...")
    for q in tqdm(all_queries, desc="Language check"):
        result = enrich_language(q)
        if result is not None:  # åªä¿ç•™ä¸­æ–‡æŸ¥è©¢
            enriched.append(result)

    print(f"âœ… ä¿ç•™ {len(enriched)} æ¢ç¹é«”ä¸­æ–‡æŸ¥è©¢")

    print("\nğŸ§  å»ºç«‹ Embedding å‘é‡ä¸­...")
    for item in tqdm(enriched, desc="Embedding"):
        q = item["query"]
        vec = embed_query(q)
        if vec:
            vectors[q] = vec
        time.sleep(0.5)

    # === å„²å­˜æª”æ¡ˆï¼ˆä½¿ç”¨é…ç½®çš„è·¯å¾‘ï¼‰===
    csv_path = config.data_dir / config.output_files["query_pool"]
    json_path = config.data_dir / config.output_files["query_vectors"]

    df = pd.DataFrame(enriched)
    df.to_csv(csv_path, index=False, encoding="utf-8-sig")

    with open(json_path, "w", encoding="utf-8") as f:
        json.dump(vectors, f, ensure_ascii=False, indent=2)

    print(f"\nâœ… æŸ¥è©¢æ± èˆ‡å‘é‡å»ºç«‹å®Œæˆï¼")
    print(f"ğŸ“ {csv_path}ï¼ˆ{len(df)} æ¢ï¼‰")
    print(f"ğŸ“ {json_path}ï¼ˆ{len(vectors)} æ¢ï¼‰")

    # === é©—è­‰è³‡æ–™ä¸€è‡´æ€§ ===
    if len(df) == len(vectors):
        print("ğŸ§© é©—è­‰æˆåŠŸï¼šæŸ¥è©¢èˆ‡å‘é‡æ•¸é‡ä¸€è‡´ âœ…")
    else:
        missing = len(df) - len(vectors)
        print(f"âš ï¸ æœ‰ {missing} æ¢æŸ¥è©¢ç¼ºå°‘å‘é‡ï¼Œå»ºè­°åŸ·è¡Œ repair_vectors.py ä¿®å¾©ã€‚")

# =======================================================
if __name__ == "__main__":
    main()
