# -*- coding: utf-8 -*-
"""
ç”Ÿæˆ 10 å€‹ FAQ å•é¡Œçš„ç­”æ¡ˆ
"""

import os
import sys
import io
import json
from pathlib import Path
from openai import OpenAI
from dotenv import load_dotenv

# Windows UTF-8 æ”¯æ´
if sys.platform == "win32":
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')

ROOT_DIR = Path(__file__).parent.absolute()
load_dotenv(ROOT_DIR / "config" / "secrets.env")

# åˆå§‹åŒ– OpenAI
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# 10 å€‹å•é¡Œåˆ—è¡¨
questions = [
    "é«˜å£“æ»…èŒçš„æº«åº¦å’Œæ™‚é–“éœ€æ±‚æ˜¯ä»€éº¼ï¼Ÿ",
    "é«˜å£“è’¸æ°£æ»…èŒä¿å­˜æœŸé™ï¼Ÿ",
    "How to choose an autoclave?",
    "What are the factors of autoclave?",
    "Which is better Class N or B autoclave?",
    "What are the steps to use an autoclave?",
    "How often should the autoclave be cleaned and maintained?",
    "How to troubleshoot an autoclave?",
    "What are the safety precautions when handling an autoclave?",
    "What cannot be sterilized in an autoclave?"
]

print("\n" + "=" * 60)
print("ğŸ“ ç”Ÿæˆ 10 å€‹ FAQ ç­”æ¡ˆ")
print("=" * 60)

faq_results = []

for i, question in enumerate(questions, 1):
    print(f"\næ­£åœ¨ç”Ÿæˆ FAQ {i}/10: {question}")

    # åˆ¤æ–·èªè¨€
    is_english = any(ord(char) < 128 and char.isalpha() for char in question)
    answer_lang = "è‹±æ–‡" if is_english else "ç¹é«”ä¸­æ–‡"

    # ç”Ÿæˆæç¤º
    prompt = f"""ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„é«˜å£“æ»…èŒé‹ï¼ˆAutoclaveï¼‰é ˜åŸŸå°ˆå®¶ã€‚è«‹ç‚ºä»¥ä¸‹å•é¡Œæä¾›å°ˆæ¥­ã€å¯¦ç”¨ã€å…·é«”çš„å›ç­”ã€‚

å•é¡Œï¼š{question}

å›ç­”è¦æ±‚ï¼š
1. èªè¨€ï¼šä½¿ç”¨{answer_lang}å›ç­”
2. å­—æ•¸ï¼š200-300 å­—
3. å…§å®¹ï¼šå¯¦ç”¨ã€å°ˆæ¥­ã€å…·é«”ï¼Œæä¾›å¯æ“ä½œçš„å»ºè­°
4. å¦‚æœé©ç”¨ï¼ŒæåŠå…·é«”æ¨™æº–æˆ–è¦ç¯„ï¼ˆå¦‚ ISOã€ENã€FDA ç­‰ï¼‰
5. é¿å…éåº¦æŠ€è¡“ç´°ç¯€ï¼Œä½†è¦å°ˆæ¥­æº–ç¢º
6. ä½¿ç”¨å°ç£ç¹é«”ä¸­æ–‡å°ˆæ¥­è¡“èªï¼ˆå¦‚æœæ˜¯ä¸­æ–‡å•é¡Œï¼‰
7. é¿å…ä½¿ç”¨ã€Œæœ¬æ–‡ã€ã€ã€Œä»¥ä¸‹ã€ç­‰æŒ‡æ¶‰æ€§è©å½™
8. é¿å… AI å¯«ä½œç—•è·¡ï¼ˆå¦‚ã€Œæ·±å…¥æ¢ç´¢ã€ã€ã€Œå…¨é¢æ€§çš„ã€ï¼‰

è«‹ç›´æ¥æä¾›ç­”æ¡ˆï¼Œä¸éœ€è¦é‡è¤‡å•é¡Œã€‚
"""

    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„é«˜å£“æ»…èŒé‹é ˜åŸŸå°ˆå®¶ï¼Œæä¾›å¯¦ç”¨ä¸”å°ˆæ¥­çš„å»ºè­°ã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=800
        )

        answer = response.choices[0].message.content.strip()

        faq_results.append({
            "question": question,
            "answer": answer,
            "language": "en" if is_english else "zh-TW"
        })

        print(f"âœ… ç”Ÿæˆå®Œæˆï¼ˆ{len(answer)} å­—ï¼‰")

    except Exception as e:
        print(f"âŒ ç”Ÿæˆå¤±æ•—: {e}")
        faq_results.append({
            "question": question,
            "answer": f"[ç”Ÿæˆå¤±æ•—: {str(e)}]",
            "language": "en" if is_english else "zh-TW"
        })

# å„²å­˜çµæœ
output_file = ROOT_DIR / "data" / "faq_10_questions.json"
with open(output_file, "w", encoding="utf-8") as f:
    json.dump(faq_results, f, ensure_ascii=False, indent=2)

print(f"\n\nâœ… ç”Ÿæˆå®Œæˆï¼çµæœå·²å„²å­˜è‡³ï¼š{output_file}")

# åŒæ™‚ç”Ÿæˆ Markdown æ ¼å¼
md_output_file = ROOT_DIR / "data" / "faq_10_questions.md"
with open(md_output_file, "w", encoding="utf-8") as f:
    f.write("# é«˜å£“æ»…èŒé‹ FAQï¼ˆ10 å€‹å•é¡Œï¼‰\n\n")

    for i, faq in enumerate(faq_results, 1):
        f.write(f"## Q{i}: {faq['question']}\n\n")
        f.write(f"**A:** {faq['answer']}\n\n")
        f.write("---\n\n")

print(f"âœ… Markdown æ ¼å¼å·²å„²å­˜è‡³ï¼š{md_output_file}")

# åœ¨æ§åˆ¶å°è¼¸å‡ºçµæœ
print("\n" + "=" * 60)
print("ğŸ“‹ FAQ å…§å®¹é è¦½")
print("=" * 60)

for i, faq in enumerate(faq_results, 1):
    print(f"\n\n### Q{i}: {faq['question']}\n")
    print(f"A: {faq['answer']}\n")
    print("-" * 60)
